{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65eaa1f5",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0420118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e228385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x10ed441a0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10ed44c20> root_client=<openai.OpenAI object at 0x10e30da90> root_async_client=<openai.AsyncOpenAI object at 0x10ed44980> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4005c253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key is set (masked: sk-pr...y8AA)\n"
     ]
    }
   ],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "# Check if API key is properly set\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key or api_key.startswith(\"sk-\") == False:\n",
    "    print(\"Warning: OpenAI API key is not properly set or formatted\")\n",
    "    print(\"API key should start with 'sk-'\")\n",
    "    # If you want to set it manually for testing\n",
    "    # os.environ['OPENAI_API_KEY'] = \"your-api-key-here\"  # Replace with your actual API key\n",
    "else:\n",
    "    # Mask the key when printing for security\n",
    "    masked_key = api_key[:5] + \"...\" + api_key[-4:] if len(api_key) > 9 else \"****\"\n",
    "    print(f\"API key is set (masked: {masked_key})\")\n",
    "    \n",
    "    # Now attempt to make the API call\n",
    "    result = llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051084a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a class of artificial intelligence systems designed to generate new content, such as text, images, music, or other data types, often with a high degree of realism. Unlike discriminative models, which are designed to classify data or make predictions, generative AI models learn the underlying patterns and structures of input data to produce novel outputs.\\n\\nSome of the most common techniques and models used in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These involve two neural networks—a generator and a discriminator—that are trained together. The generator creates new data instances, while the discriminator evaluates them. The goal is for the generator to produce data indistinguishable from real data to the discriminator.\\n\\n2. **Variational Autoencoders (VAEs):** These are designed to encode input data into a compressed latent space and then decode it back to the original form. By sampling from the latent space, VAEs can generate new data that resembles the input data.\\n\\n3. **Transformer Models:** Originally designed for natural language processing tasks, transformer architectures, such as GPT (Generative Pre-trained Transformer), have been adapted to generate highly relevant and coherent text-based content. These models predict the next word in a sequence, allowing them to generate new text passages.\\n\\nGenerative AI has a wide range of applications, including:\\n\\n- **Text Generation:** Creating articles, stories, or even code based on prompts.\\n- **Image Generation:** Producing realistic or stylized images from text descriptions or random noise.\\n- **Music and Audio:** Composing new musical pieces or synthesizing voices.\\n- **Data Augmentation:** Enhancing training datasets, especially in scenarios where limited data is available.\\n\\nDespite its potential, generative AI raises ethical concerns, particularly around issues such as misinformation, copyright, and the ability to create deepfakes, which are manipulated media made to look like real scenes or events.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 385, 'prompt_tokens': 13, 'total_tokens': 398, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-C4ANmPxnT6vGXvnMnab1axvUPWJ3V', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--8390b973-6fb0-4f6a-bda6-b7b4490b2078-0' usage_metadata={'input_tokens': 13, 'output_tokens': 385, 'total_tokens': 398, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9351e7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are an expert AI Engineer. Provide me answer based upon the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ChatPrompt Template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"you are an expert AI Engineer. Provide me answer based upon the question\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d957b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is an advanced platform created by the developers of LangChain, designed to enhance and streamline the development of language model applications. It provides a comprehensive suite of tools that allow developers to manage, evaluate, and optimize large language model (LLM) applications effectively. Key features include robust instrumentation for tracing, tools for performing evaluations using both human feedback and automated tests, and the capability to handle adaptive memory management. Langsmith is aimed at developers seeking to build reliable, efficient, and high-quality language model applications.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 33, 'total_tokens': 135, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6c1b4040d0', 'id': 'chatcmpl-C4AeEVYY24eA3owAkuXB1NuYR1YrR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--7e55e4bb-5de9-493b-b6a2-f4c1c2774960-0' usage_metadata={'input_tokens': 33, 'output_tokens': 102, 'total_tokens': 135, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt  | llm\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "423293ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a tool developed by LangChain, aimed at assisting developers in building and improving language model-based applications. It provides a platform for testing, monitoring, and evaluating the performance of applications that utilize AI models. Langsmith is designed to support developers in understanding how their models are performing in real-world scenarios, identify any issues, and fine-tune their systems for better efficiency and accuracy. By offering features like detailed analytics and diagnostic tools, Langsmith helps streamline the development process of language model applications, making it easier to deploy robust and reliable AI solutions.\n"
     ]
    }
   ],
   "source": [
    "## String Output Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "outputParser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | outputParser\n",
    "\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
